{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing and Feature Selection Detecting Depression",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCPrXGuFAxut",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJMHYSxLrsNf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4b98ab01-3ede-49f7-f0e3-ebd96540b13f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyA99T2cgKjA",
        "colab_type": "text"
      },
      "source": [
        "## Importing the libraries. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImQbnkm_8ZnF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "15a53d12-ddbb-4a28-9cf2-06bd9f5cf35e"
      },
      "source": [
        "!pip install chart_studio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting chart_studio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/ce/330794a6b6ca4b9182c38fc69dd2a9cbff60fd49421cb8648ee5fee352dc/chart_studio-1.1.0-py3-none-any.whl (64kB)\n",
            "\r\u001b[K     |█████                           | 10kB 18.4MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 40kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 51kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 61kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from chart_studio) (1.3.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from chart_studio) (4.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from chart_studio) (1.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from chart_studio) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->chart_studio) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->chart_studio) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->chart_studio) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->chart_studio) (2.9)\n",
            "Installing collected packages: chart-studio\n",
            "Successfully installed chart-studio-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mttd0yFHE9un",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c47bd97-c04f-4ccf-d733-44f62548ba94"
      },
      "source": [
        "#importing all libraries\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import chart_studio.plotly as py\n",
        "import plotly.graph_objs as go\n",
        "import itertools\n",
        "from scipy import stats\n",
        "from ast import literal_eval\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EC2X9Zo-E_p1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "53102229-6bd4-4525-955f-b96767d97484"
      },
      "source": [
        "!pip install nltk\n",
        "import nltk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMwbL_-gFMHv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "522441a7-3d35-4b91-9073-ca8fc9d1f0e2"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFqZnvveFPyL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "import json\n",
        "\n",
        "import csv\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import keras.utils\n",
        "from keras import utils as np_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEihtZzgBCt8",
        "colab_type": "text"
      },
      "source": [
        "### Functions for Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noVtd056HfA7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "import nltk\n",
        "import spacy\n",
        "\n",
        "#Input a document and receive a list of lists detailing individual word tokens.\n",
        "#Note, this is a Whitespace tokenizer, which preserves contractions.\n",
        "def tokenize(doc):\n",
        "  return nltk.tokenize.WhitespaceTokenizer().tokenize(doc)\n",
        "\n",
        "\n",
        "\n",
        "#Input a document and receive a list of lists detailing individual sentence tokens.\n",
        "def sentence_tokenize(doc):\n",
        "  return nltk.tokenize.sent_tokenize(doc)\n",
        "\n",
        "\n",
        "\n",
        "#Input a string or document and output a list of tokens that has split contractions.\n",
        "#Note, this is a WordPunct tokenizer, which splits apart contractions. However, the stopwords included in \n",
        "#NLTK should delete the split contractions if converted to lowercase.\n",
        "def split_contractions(doc):\n",
        "  return nltk.tokenize.wordpunct_tokenize(doc)\n",
        "\n",
        "\n",
        "\n",
        "#Input a list of list containing tokenized document or corpus. Return all tokens if not of the format: [token] or <token>\n",
        "#This is an attempt to remove semantic information that would skew training.\n",
        "#NOTE: this should be done before removing punctuation, otherwise you will not find the correct tokens.\n",
        "def remove_semantics(tokens):\n",
        "    #first remove semantic information surrounded by brackets: []\n",
        "    tokens =  [token for token in tokens if not token.startswith('[') and  not token.endswith(']')]\n",
        "    #then remove semantic information surround by: <>\n",
        "    return [token for token in tokens if not token.startswith('<') and  not token.endswith('>')]\n",
        "\n",
        "\n",
        "\n",
        "#Input a tokenized text as a list of lists. \n",
        "#POS tag, and then return a list containing all tokens that are not proper nouns.\n",
        "def remove_proper_nouns(tokens):\n",
        "\tpos = nltk.pos_tag(tokens)\n",
        "\tto_remove = ['NNP', 'NNPS']\n",
        "\n",
        "\treturn [pos[0] for pos in pos if pos[1] not in to_remove]\n",
        "\n",
        "\n",
        "\n",
        "#Input a list of tokens and output a single string\n",
        "def list_to_string(tokens):\n",
        "    string_ = \"\"\n",
        "    whitespace = \" \"\n",
        "    for token in tokens:\n",
        "        string_ = string_ + token + whitespace\n",
        "        \n",
        "    return string_\n",
        "\n",
        "\n",
        "\n",
        "#Convert all tokens to lowercase. Assumes that tokenizing has already occurred.\n",
        "def lower_case(tokens):\n",
        "     \n",
        "    return [token.lower() for token in tokens]\n",
        "\n",
        "\n",
        "\n",
        "#This method removes NLTK stopwords. Currently, this method works for English stopwords.\n",
        "#More work can be done to input a \"language\" parameter to make it more customizable by language.\n",
        "def remove_stopwords(tokens):\n",
        "    #Create stopwords set for English.\n",
        "    #This list can be modified in the english.txt file for NLTK, or use this syntax:\n",
        "    #stopwords.extend(your_list_here)\n",
        "    stopwords = nltk.corpus.stopwords.words('english')\n",
        "    \n",
        "    #add bad tokens into stopwords list\n",
        "    stopwords.extend(['mmm', 'k', 'xxx'])\n",
        "\n",
        "    #update stop words to keep certain words\n",
        "    keep_list = ['uh', 'uhhh', 'um', 'ummm', 'i', \"i'm\", 'me', 'myself', 'mine', 'my',\n",
        "                 'we', 'us', 'ourselves', 'ourself', 'ours', 'our', 'he', 'him', 'himself', 'his','she', 'her', 'herself', 'hers', 'her', 'they', 'them', 'themselves', 'themself', 'theirs', 'their', \t\t\t'always', 'nothing', 'completely', 'never', 'all', 'every', 'none', 'only']\n",
        "\n",
        "    stopwords = [word for word in stopwords if word not in keep_list]\n",
        "    stops = set(stopwords)\n",
        "\n",
        "    return [token for token in tokens if token not in stops]\n",
        "\n",
        "\n",
        "\n",
        "#Remove punctuation and replace it with an empty string character.\n",
        "#Example: can't --> cant\n",
        "def strip_punctuation(tokens):\n",
        "    #Create punctuation list: !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
        "    punctuation = string.punctuation\n",
        "\n",
        "    #See docs: str.maketrans() will make a table to pass to str.translate()\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "\n",
        "    return [token.translate(table) for token in tokens]\n",
        "\n",
        "\n",
        "\n",
        "#Strip any non-alphabetic characters.\n",
        "def remove_numbers(tokens):\n",
        "    return [token for token in tokens if token.isalpha()]\n",
        "\n",
        "\n",
        "\n",
        "#Input a list of tokens, output a list of tokens minus people and places.\n",
        "#NOTE: SpaCy's entity recognition should be done before converting tokens to lowercase, and at this time\n",
        "#does not recognize lowercase entities. So it will recognize United States, but not UNITED STATES or united states. Likewise, it may recognize Sarah and SARAH, but not sarah.\n",
        "def remove_people_places(doc):\n",
        "    nlp = spacy.load('en')\n",
        "    \n",
        "    document = list_to_string(doc)\n",
        "    document = nlp(document)\n",
        "    \n",
        "    #create list of removable words\n",
        "    ppl_plcs = ['PERSON', 'GPE']\n",
        "    to_remove = [ent.text for ent in document.ents if ent.label_ in ppl_plcs]\n",
        "    \n",
        "    #now remove those words and \n",
        "    return [token for token in doc if token not in to_remove]\n",
        "\n",
        "\n",
        "\n",
        "#Input a file that has text on separate lines (separated by breakline characters or otherwise).\n",
        "#Output number of lines in that file.\n",
        "#def count_sentences(filename):\n",
        "    #sentences = 0\n",
        "    #reader = csv.reader(filename,delimiter = \",\")\n",
        "    #data = list(reader)\n",
        "    #sentences = len(data)\n",
        "\n",
        "    #return sentences\n",
        "\n",
        "  \n",
        "\n",
        "#Input a custom list of words you would like to count in a list of tokenized words.\n",
        "#Outputs the total count of the words in your_list based on the frequency in tokens.\n",
        "def list_in_text(your_list, tokens):\n",
        "    count = 0\n",
        "\n",
        "    for word in your_list:\n",
        "        for token in tokens:\n",
        "            if token == word:\n",
        "                count += 1\n",
        "\n",
        "    return count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3YgiaXUBQGV",
        "colab_type": "text"
      },
      "source": [
        "### Feature Extraction for the time taken by each participant to talk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89mZtgY6ERPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#append participant number from filename for indexing\n",
        "participant_num = []\n",
        "\n",
        "#count total time per transcript\n",
        "total_time = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pENYHyVED4Rn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#change directory\n",
        "change_text_dir = '/content/drive/My Drive/transcripts/'\n",
        "change_dir = os.chdir(change_text_dir)\n",
        "\n",
        "#get current working directory\n",
        "this_dir = os.getcwd()\n",
        "filenames = os.listdir(this_dir)\n",
        "\n",
        "#sort filenames for sorting vectors\n",
        "filenames = sorted(filenames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f09uylFGEBiT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for filename in filenames:\n",
        "    if filename.endswith('.csv'):\n",
        "        \n",
        "        #add participant id number to list\n",
        "        participant_num.append(int(filename[:3]))\n",
        "            \n",
        "        #read in tab-delimited files\n",
        "        df = pd.read_csv(filename, delimiter='\\t')\n",
        "      \n",
        "        #drop unnecessary columns\n",
        "        df.drop(['speaker', 'value'], axis=1, inplace=True)\n",
        "\n",
        "        #create time difference column\n",
        "        df['time_per_sent'] = df.stop_time - df.start_time\n",
        "\n",
        "        #get total transcript time in minutes\n",
        "        #rounded to five decimal places\n",
        "        time = np.round((df.time_per_sent.sum() / 60.0), 5)\n",
        "\n",
        "        total_time.append(time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQlSXqpBECsv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create dataframe of transcript times for EDA later on\n",
        "transcript_features = pd.DataFrame({'id': participant_num,\n",
        "                                 'total_time': total_time})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afViBnL0EBtE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "83be6467-be5b-458a-b886-d66814506fae"
      },
      "source": [
        "transcript_features.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>total_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>300</td>\n",
              "      <td>4.94333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>301</td>\n",
              "      <td>9.55650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>302</td>\n",
              "      <td>5.37210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>303</td>\n",
              "      <td>13.18600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>304</td>\n",
              "      <td>8.77833</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id  total_time\n",
              "0  300     4.94333\n",
              "1  301     9.55650\n",
              "2  302     5.37210\n",
              "3  303    13.18600\n",
              "4  304     8.77833"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlgWEdKpeR2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transcript_time = transcript_features.to_csv('/content/drive/My Drive/time.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd9cHj9w9mPq",
        "colab_type": "text"
      },
      "source": [
        "# Feature extraction for sentence count and average words spoken"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moShOWZKKoLZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#lists to append each transcript feature to\n",
        "#append participant number from filename for indexing\n",
        "participant_num = []\n",
        "#count total words, words per sentence\n",
        "total_words, wps = [], []\n",
        "#filler words, personal prnouns lists\n",
        "pronouns1, pronouns2, pronouns3 = [], [], []\n",
        "\n",
        "fillers, absolute_words = [], []\n",
        "\n",
        "#create lists containing fillers, pronouns\n",
        "filler_list = ['uh', 'uhhh', 'um', 'ummm','ugh' ]\n",
        "\n",
        "#source: https://en.wikipedia.org/wiki/English_personal_pronouns\n",
        "singular_list = ['i', \"i'm\", 'me', 'myself', 'mine', 'my','im']\n",
        "plural_list = ['we', 'us', 'ourselves', 'ourself', 'ours', 'our']\n",
        "third_list = ['he', 'him', 'himself', 'his', 'she', 'her', 'herself', 'hers', 'her',\n",
        "             'they', 'them', 'themselves', 'themself', 'theirs', 'their']\n",
        "laughter_list = ['laughter']\n",
        "\n",
        "#create list for absolutist words\n",
        "absolute_list = ['always', 'nothing', 'completely', 'never', 'all', 'every', 'none', 'only']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUm6wRDWXXe-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_total = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da2PGIv9KoSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create a list of *strings*, each one containing the transcript of a participant\n",
        "for filename in filenames:\n",
        "    if filename.endswith('.csv'):\n",
        "        #add participant id number to list\n",
        "        participant_num.append(int(filename[:3]))\n",
        "        #read in tab-delimited files\n",
        "        df = pd.read_csv(filename, delimiter='\\t')\n",
        "        #drop unnecessary columns\n",
        "        df.drop(['speaker'], axis=1, inplace=True)\n",
        "        sentence_count = df.value.count()\n",
        "       \n",
        "        #whitespace tokenize\n",
        "        tokens = df.value.apply(lambda x : tokenize(str(x)))\n",
        "        total = len(tokens)\n",
        "        total_words.append(total)\n",
        "\n",
        "        average_words = total / sentence_count\n",
        "        \n",
        "\n",
        "        \n",
        "    sentence_total.append(sentence_count)\n",
        "    wps.append(average_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoWVwTpc8OcQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a536c4d6-3449-4251-9531-5647cace9fcc"
      },
      "source": [
        "sentence_total.pop()\n",
        "wps.pop()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzSHbdAR9nn-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f598073-11e2-47b2-8439-6e9af32f1cda"
      },
      "source": [
        "len(sentence_total)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "189"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHgGZy7chH3-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transcript_features['sentence_count'] = sentence_total\n",
        "transcript_features['wps'] = wps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzOeJTH3m4bj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "89ab5b64-5363-411c-afff-fae04f68f611"
      },
      "source": [
        "transcript_features.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>total_time</th>\n",
              "      <th>sentence_count</th>\n",
              "      <th>wps</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>300</td>\n",
              "      <td>4.94333</td>\n",
              "      <td>295</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>301</td>\n",
              "      <td>9.55650</td>\n",
              "      <td>174</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>302</td>\n",
              "      <td>5.37210</td>\n",
              "      <td>181</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>303</td>\n",
              "      <td>13.18600</td>\n",
              "      <td>186</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>304</td>\n",
              "      <td>8.77833</td>\n",
              "      <td>191</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id  total_time  sentence_count  wps\n",
              "0  300     4.94333             295  1.0\n",
              "1  301     9.55650             174  1.0\n",
              "2  302     5.37210             181  1.0\n",
              "3  303    13.18600             186  1.0\n",
              "4  304     8.77833             191  1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nI3I-1d9x2z",
        "colab_type": "text"
      },
      "source": [
        "### Feature extraction for counting the filler words "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td4idc1snwdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transcripts_to_dataframe(directory):\n",
        "    rows_list = []\n",
        "        \n",
        "    filenames = os.listdir(directory)\n",
        "    \n",
        "    if \".DS_Store\" in filenames:\n",
        "        filenames.remove(\".DS_Store\")\n",
        "        \n",
        "    for filename in filenames:\n",
        "        transcript_path = os.path.join(directory, filename)\n",
        "        transcript = pd.read_csv(transcript_path, sep='\\t')\n",
        "        m = re.search(\"(\\d{3})_TRANSCRIPT.csv\", filename)\n",
        "        if m:\n",
        "            person_id = m.group(1)\n",
        "            p = {}\n",
        "            question = \"\"\n",
        "            answer = \"\"\n",
        "            lines = len(transcript)\n",
        "            for i in range(0, lines):\n",
        "                row = transcript.iloc[i]\n",
        "                if (row[\"speaker\"] == \"Ellie\") or (i == lines - 1):\n",
        "                    p[\"personId\"] = person_id\n",
        "                    if \"(\" in str(question):\n",
        "                        question = question[question.index(\"(\") + 1:question.index(\")\")]\n",
        "                    p[\"question\"] = question\n",
        "                    p[\"answer\"] = answer\n",
        "                    if question != \"\":\n",
        "                        rows_list.append(p)\n",
        "                    p = {}\n",
        "                    answer = \"\"\n",
        "                    question = row[\"value\"]\n",
        "                else:\n",
        "                    answer = str(answer) + \" \" + str(row[\"value\"])\n",
        "\n",
        "    all_participants = pd.DataFrame(rows_list, columns=['personId', 'question', 'answer'])\n",
        "    all_participants.to_csv(directory + 'all.csv', sep=',')\n",
        "    print(\"File was created\")\n",
        "    return all_participants"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Mowrj-GnwhO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d4f6d105-39ca-4de3-e2f2-888be894015e"
      },
      "source": [
        "#loading the data\n",
        "data_path = \"/content/drive/My Drive/transcripts/\"\n",
        "all_participants = transcripts_to_dataframe(data_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File was created\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCHshOEk_AUs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_participants['tokenized_answer'] = all_participants.apply(lambda row: nltk.word_tokenize(row['answer']), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dj8g3xh2Fg_o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "13cbc3b6-4e92-42b9-c432-a1c18dd11351"
      },
      "source": [
        "all_participants.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>personId</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>tokenized_answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>300</td>\n",
              "      <td>hi i'm ellie thanks for coming in today</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>300</td>\n",
              "      <td>i was created to talk to people in a safe and ...</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>300</td>\n",
              "      <td>think of me as a friend i don't judge i can't ...</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>300</td>\n",
              "      <td>i'm here to learn about people and would love ...</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>300</td>\n",
              "      <td>i'll ask a few questions to get us started and...</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  personId  ... tokenized_answer\n",
              "0      300  ...               []\n",
              "1      300  ...               []\n",
              "2      300  ...               []\n",
              "3      300  ...               []\n",
              "4      300  ...               []\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FQTam66wo0R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "outputId": "e92e2c58-2152-4e80-b388-a17bdb411aa4"
      },
      "source": [
        "#Selecting the data from the data from based on the questions asked  ['where', 'when', 'how', 'why', 'are', 'what', 'do', 'have', 'can', 'did', 'is', 'could', 'so', 'tell', 'who', 'has']\n",
        "interrogative = [\"where\", \"when\", \"how\",\"why\",\"are\",\"what\",\"do\",\"have\",\"can\",\"did\",\"is\", \"could\", \"so\", \"tell\", \"who\", \"has\"]\n",
        "rslt_df = all_participants[all_participants.question.str.contains('|'.join(interrogative),na=False)]\n",
        "rslt_df['answer'].replace('', np.nan, inplace=True)\n",
        "rslt_df.dropna(subset = [\"answer\"], inplace=True)\n",
        "rslt_df.reset_index(drop=True, inplace=True)\n",
        "rslt_df\n",
        "#rslt_df = rslt_df.to_csv(\"/content/drive/My Drive/rslt_df.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py:6746: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>personId</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>tokenized_answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>300</td>\n",
              "      <td>how are you doing today</td>\n",
              "      <td>good</td>\n",
              "      <td>[good]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>300</td>\n",
              "      <td>where are you from originally</td>\n",
              "      <td>atlanta georgia</td>\n",
              "      <td>[atlanta, georgia]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>300</td>\n",
              "      <td>why'd you move to l_a</td>\n",
              "      <td>um my parents are from here um</td>\n",
              "      <td>[um, my, parents, are, from, here, um]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>300</td>\n",
              "      <td>how do you like l_a</td>\n",
              "      <td>i love it</td>\n",
              "      <td>[i, love, it]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>300</td>\n",
              "      <td>what are some things you really like about l_a</td>\n",
              "      <td>i like the weather i like the opportunities u...</td>\n",
              "      <td>[i, like, the, weather, i, like, the, opportun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8698</th>\n",
              "      <td>390</td>\n",
              "      <td>that's so good to hear</td>\n",
              "      <td>mm</td>\n",
              "      <td>[mm]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8699</th>\n",
              "      <td>390</td>\n",
              "      <td>is there anything you regret</td>\n",
              "      <td>um hm no um except meeting that one woman uh</td>\n",
              "      <td>[um, hm, no, um, except, meeting, that, one, w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8700</th>\n",
              "      <td>390</td>\n",
              "      <td>what advice would you give to yourself ten or ...</td>\n",
              "      <td>uh i don't know probably try a little harder ...</td>\n",
              "      <td>[uh, i, do, n't, know, probably, try, a, littl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8701</th>\n",
              "      <td>390</td>\n",
              "      <td>tell me how you spend your ideal weekend</td>\n",
              "      <td>oh um getting out of town um going going away...</td>\n",
              "      <td>[oh, um, getting, out, of, town, um, going, go...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8702</th>\n",
              "      <td>390</td>\n",
              "      <td>what are you most proud of in your life</td>\n",
              "      <td>um well my daughter's a great source of pride...</td>\n",
              "      <td>[um, well, my, daughter, 's, a, great, source,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8703 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     personId  ...                                   tokenized_answer\n",
              "0         300  ...                                             [good]\n",
              "1         300  ...                                 [atlanta, georgia]\n",
              "2         300  ...             [um, my, parents, are, from, here, um]\n",
              "3         300  ...                                      [i, love, it]\n",
              "4         300  ...  [i, like, the, weather, i, like, the, opportun...\n",
              "...       ...  ...                                                ...\n",
              "8698      390  ...                                               [mm]\n",
              "8699      390  ...  [um, hm, no, um, except, meeting, that, one, w...\n",
              "8700      390  ...  [uh, i, do, n't, know, probably, try, a, littl...\n",
              "8701      390  ...  [oh, um, getting, out, of, town, um, going, go...\n",
              "8702      390  ...  [um, well, my, daughter, 's, a, great, source,...\n",
              "\n",
              "[8703 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV-qVqZhMCbc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "209a1c82-064c-40cd-a67d-4ef0cec96c23"
      },
      "source": [
        "rslt_df.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>personId</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>tokenized_answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7410</th>\n",
              "      <td>465</td>\n",
              "      <td>that sounds really hard</td>\n",
              "      <td>it was cool it was fun life</td>\n",
              "      <td>[it, was, cool, it, was, fun, life]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6721</th>\n",
              "      <td>452</td>\n",
              "      <td>tell me about the last time you felt really happy</td>\n",
              "      <td>uh right now i feel really happy</td>\n",
              "      <td>[uh, right, now, i, feel, really, happy]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7953</th>\n",
              "      <td>478</td>\n",
              "      <td>what got you to seek help</td>\n",
              "      <td>uh i was i was just um very sad very depresse...</td>\n",
              "      <td>[uh, i, was, i, was, just, um, very, sad, very...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>316</td>\n",
              "      <td>is going to a therapist helping you</td>\n",
              "      <td>to a degree but not as much as i like</td>\n",
              "      <td>[to, a, degree, but, not, as, much, as, i, like]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7802</th>\n",
              "      <td>472</td>\n",
              "      <td>tell me about your kids</td>\n",
              "      <td>um my daughter is um thirty nine beautiful br...</td>\n",
              "      <td>[um, my, daughter, is, um, thirty, nine, beaut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>441</th>\n",
              "      <td>303</td>\n",
              "      <td>can you give me an example of that</td>\n",
              "      <td>well um by you being the first teacher your k...</td>\n",
              "      <td>[well, um, by, you, being, the, first, teacher...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3145</th>\n",
              "      <td>373</td>\n",
              "      <td>what made you decide to do that</td>\n",
              "      <td>ugh just a abundance of &lt;laughter&gt; reasons th...</td>\n",
              "      <td>[ugh, just, a, abundance, of, &lt;, laughter, &gt;, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6097</th>\n",
              "      <td>433</td>\n",
              "      <td>like what</td>\n",
              "      <td>uh like building my car differently um gettin...</td>\n",
              "      <td>[uh, like, building, my, car, differently, um,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8250</th>\n",
              "      <td>364</td>\n",
              "      <td>how old were you when you joined the military</td>\n",
              "      <td>that um seventeen i started when after high s...</td>\n",
              "      <td>[that, um, seventeen, i, started, when, after,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1272</th>\n",
              "      <td>326</td>\n",
              "      <td>what do you think of today's kids</td>\n",
              "      <td>huh</td>\n",
              "      <td>[huh]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     personId  ...                                   tokenized_answer\n",
              "7410      465  ...                [it, was, cool, it, was, fun, life]\n",
              "6721      452  ...           [uh, right, now, i, feel, really, happy]\n",
              "7953      478  ...  [uh, i, was, i, was, just, um, very, sad, very...\n",
              "564       316  ...   [to, a, degree, but, not, as, much, as, i, like]\n",
              "7802      472  ...  [um, my, daughter, is, um, thirty, nine, beaut...\n",
              "441       303  ...  [well, um, by, you, being, the, first, teacher...\n",
              "3145      373  ...  [ugh, just, a, abundance, of, <, laughter, >, ...\n",
              "6097      433  ...  [uh, like, building, my, car, differently, um,...\n",
              "8250      364  ...  [that, um, seventeen, i, started, when, after,...\n",
              "1272      326  ...                                              [huh]\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fB0inhkWw4qs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "162b9776-1782-4bad-c240-86e5b6e23d5e"
      },
      "source": [
        "rslt_df['word_count'] = rslt_df['answer'].apply(lambda x: len(str(x).split(\" \"))-1)\n",
        "rslt_df[['answer','word_count']].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answer</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>good</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>atlanta georgia</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>um my parents are from here um</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i love it</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i like the weather i like the opportunities u...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              answer  word_count\n",
              "0                                               good           1\n",
              "1                                    atlanta georgia           2\n",
              "2                     um my parents are from here um           7\n",
              "3                                          i love it           3\n",
              "4   i like the weather i like the opportunities u...          10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoz6550fxjK5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "f70dcae3-2484-4795-cb6c-a62cb4f92193"
      },
      "source": [
        "rslt_df['fill'] = rslt_df.tokenized_answer.apply(lambda x : list_in_text(filler_list, x))\n",
        "rslt_df['single'] = rslt_df.tokenized_answer.apply(lambda x : list_in_text(singular_list, x))\n",
        "rslt_df['plural'] = rslt_df.tokenized_answer.apply(lambda x : list_in_text(plural_list, x))\n",
        "rslt_df['third'] = rslt_df.tokenized_answer.apply(lambda x : list_in_text(third_list, x))\n",
        "rslt_df['absolute'] = rslt_df.tokenized_answer.apply(lambda x : list_in_text(absolute_list, x))\n",
        "rslt_df['laughter_count'] = rslt_df.tokenized_answer.apply(lambda x : list_in_text(laughter_list, x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pea8umVLLeiB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c941045c-4fbf-410f-98e3-8d72ce2c3ed9"
      },
      "source": [
        "rslt_df['laughter_count'].sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1741    0\n",
              "2353    0\n",
              "3234    0\n",
              "7037    1\n",
              "7609    0\n",
              "523     0\n",
              "4492    0\n",
              "4093    0\n",
              "6176    1\n",
              "3268    0\n",
              "Name: laughter_count, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZX610Haw08-N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "66893c87-8007-416c-82f9-b4586142d5b4"
      },
      "source": [
        "rslt_df.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>personId</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>tokenized_answer</th>\n",
              "      <th>word_count</th>\n",
              "      <th>fill</th>\n",
              "      <th>single</th>\n",
              "      <th>plural</th>\n",
              "      <th>third</th>\n",
              "      <th>absolute</th>\n",
              "      <th>laughter_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1737</th>\n",
              "      <td>336</td>\n",
              "      <td>have you noticed any changes in your behavior ...</td>\n",
              "      <td>behavior what</td>\n",
              "      <td>[behavior, what]</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>300</td>\n",
              "      <td>what are you like when you don't sleep well</td>\n",
              "      <td>irritated um lazy</td>\n",
              "      <td>[irritated, um, lazy]</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8456</th>\n",
              "      <td>399</td>\n",
              "      <td>why</td>\n",
              "      <td>i don't know it's just always been like that ...</td>\n",
              "      <td>[i, do, n't, know, it, 's, just, always, been,...</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5129</th>\n",
              "      <td>491</td>\n",
              "      <td>that sounds like a great situation</td>\n",
              "      <td>and i it just i moved past the fear and just ...</td>\n",
              "      <td>[and, i, it, just, i, moved, past, the, fear, ...</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5238</th>\n",
              "      <td>416</td>\n",
              "      <td>can you tell me about that</td>\n",
              "      <td>um we're relationship just wasn't doing very ...</td>\n",
              "      <td>[um, we, 're, relationship, just, was, n't, do...</td>\n",
              "      <td>79</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5064</th>\n",
              "      <td>489</td>\n",
              "      <td>why</td>\n",
              "      <td>because that makes you have attention deficit...</td>\n",
              "      <td>[because, that, makes, you, have, attention, d...</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2234</th>\n",
              "      <td>347</td>\n",
              "      <td>what do you do now</td>\n",
              "      <td>uh certified nurse's aide</td>\n",
              "      <td>[uh, certified, nurse, 's, aide]</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7483</th>\n",
              "      <td>463</td>\n",
              "      <td>what's something you feel guilty about</td>\n",
              "      <td>um this one time i &lt;sigh&gt; at my work uh it's ...</td>\n",
              "      <td>[um, this, one, time, i, &lt;, sigh, &gt;, at, my, w...</td>\n",
              "      <td>23</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2467</th>\n",
              "      <td>351</td>\n",
              "      <td>yeah i'm sorry to hear that</td>\n",
              "      <td>it's okay &lt;laughter&gt;</td>\n",
              "      <td>[it, 's, okay, &lt;, laughter, &gt;]</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1956</th>\n",
              "      <td>339</td>\n",
              "      <td>are you okay with this</td>\n",
              "      <td>yes</td>\n",
              "      <td>[yes]</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     personId  ... laughter_count\n",
              "1737      336  ...              0\n",
              "37        300  ...              0\n",
              "8456      399  ...              0\n",
              "5129      491  ...              0\n",
              "5238      416  ...              0\n",
              "5064      489  ...              0\n",
              "2234      347  ...              0\n",
              "7483      463  ...              0\n",
              "2467      351  ...              1\n",
              "1956      339  ...              0\n",
              "\n",
              "[10 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKR2_eOA2c9i",
        "colab_type": "text"
      },
      "source": [
        "##Counting the Positive and Negative Words used by participants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGZEWeC51Aeq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#change directory\n",
        "with_i_text_dir = '/content/drive/My Drive/transcripts/'\n",
        "\n",
        "#positive and negative word lists obtained from here:\n",
        "#http://www.wjh.harvard.edu/~inquirer/homecat.htm\n",
        "pos_neg_file = '/content/drive/My Drive/inquirerbasic.xls'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5A-O0Un4kz_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "21186d97-1137-4876-b8de-4bd7c4301078"
      },
      "source": [
        "df = pd.read_excel(pos_neg_file)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Entry</th>\n",
              "      <th>Source</th>\n",
              "      <th>Positiv</th>\n",
              "      <th>Negativ</th>\n",
              "      <th>Pstv</th>\n",
              "      <th>Affil</th>\n",
              "      <th>Ngtv</th>\n",
              "      <th>Hostile</th>\n",
              "      <th>Strong</th>\n",
              "      <th>Power</th>\n",
              "      <th>Weak</th>\n",
              "      <th>Submit</th>\n",
              "      <th>Active</th>\n",
              "      <th>Passive</th>\n",
              "      <th>Pleasur</th>\n",
              "      <th>Pain</th>\n",
              "      <th>Feel</th>\n",
              "      <th>Arousal</th>\n",
              "      <th>EMOT</th>\n",
              "      <th>Virtue</th>\n",
              "      <th>Vice</th>\n",
              "      <th>Ovrst</th>\n",
              "      <th>Undrst</th>\n",
              "      <th>Academ</th>\n",
              "      <th>Doctrin</th>\n",
              "      <th>Econ@</th>\n",
              "      <th>Exch</th>\n",
              "      <th>ECON</th>\n",
              "      <th>Exprsv</th>\n",
              "      <th>Legal</th>\n",
              "      <th>Milit</th>\n",
              "      <th>Polit@</th>\n",
              "      <th>POLIT</th>\n",
              "      <th>Relig</th>\n",
              "      <th>Role</th>\n",
              "      <th>COLL</th>\n",
              "      <th>Work</th>\n",
              "      <th>Ritual</th>\n",
              "      <th>SocRel</th>\n",
              "      <th>Race</th>\n",
              "      <th>...</th>\n",
              "      <th>AffOth</th>\n",
              "      <th>AffTot</th>\n",
              "      <th>WltPt</th>\n",
              "      <th>WltTran</th>\n",
              "      <th>WltOth</th>\n",
              "      <th>WltTot</th>\n",
              "      <th>WlbGain</th>\n",
              "      <th>WlbLoss</th>\n",
              "      <th>WlbPhys</th>\n",
              "      <th>WlbPsyc</th>\n",
              "      <th>WlbPt</th>\n",
              "      <th>WlbTot</th>\n",
              "      <th>EnlGain</th>\n",
              "      <th>EnlLoss</th>\n",
              "      <th>EnlEnds</th>\n",
              "      <th>EnlPt</th>\n",
              "      <th>EnlOth</th>\n",
              "      <th>EnlTot</th>\n",
              "      <th>SklAsth</th>\n",
              "      <th>SklPt</th>\n",
              "      <th>SklOth</th>\n",
              "      <th>SklTot</th>\n",
              "      <th>TrnGain</th>\n",
              "      <th>TrnLoss</th>\n",
              "      <th>TranLw</th>\n",
              "      <th>MeansLw</th>\n",
              "      <th>EndsLw</th>\n",
              "      <th>ArenaLw</th>\n",
              "      <th>PtLw</th>\n",
              "      <th>Nation</th>\n",
              "      <th>Anomie</th>\n",
              "      <th>NegAff</th>\n",
              "      <th>PosAff</th>\n",
              "      <th>SureLw</th>\n",
              "      <th>If</th>\n",
              "      <th>NotLw</th>\n",
              "      <th>TimeSpc</th>\n",
              "      <th>FormLw</th>\n",
              "      <th>Othtags</th>\n",
              "      <th>Defined</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A</td>\n",
              "      <td>H4Lvd</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>DET ART</td>\n",
              "      <td>| article: Indefinite singular article--some o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ABANDON</td>\n",
              "      <td>H4Lvd</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Negativ</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ngtv</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Weak</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>AffTot</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SUPV</td>\n",
              "      <td>|</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ABANDONMENT</td>\n",
              "      <td>H4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Negativ</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Weak</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Noun</td>\n",
              "      <td>|</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ABATE</td>\n",
              "      <td>H4Lvd</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Negativ</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Passive</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>TranLw</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SUPV</td>\n",
              "      <td>|</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ABATEMENT</td>\n",
              "      <td>Lvd</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Noun</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 186 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Entry  ...                                            Defined\n",
              "0            A  ...  | article: Indefinite singular article--some o...\n",
              "1      ABANDON  ...                                                  |\n",
              "2  ABANDONMENT  ...                                                  |\n",
              "3        ABATE  ...                                                  |\n",
              "4    ABATEMENT  ...                                                NaN\n",
              "\n",
              "[5 rows x 186 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz_ZsnYN4oSP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df375c1e-a640-4431-8d82-58679d4b80d2"
      },
      "source": [
        "print(df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11788, 186)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgGIQzfQ4ye_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2aa225cd-dccd-40c7-8e74-686e6f9304ff"
      },
      "source": [
        "#right now we have all word lists, we need to isolate just the positive and negative words\n",
        "df = df[['Entry', 'Positiv', 'Negativ', 'PosAff', 'NegAff']]\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Entry</th>\n",
              "      <th>Positiv</th>\n",
              "      <th>Negativ</th>\n",
              "      <th>PosAff</th>\n",
              "      <th>NegAff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ABANDON</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Negativ</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ABANDONMENT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Negativ</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ABATE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Negativ</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ABATEMENT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Entry Positiv  Negativ PosAff NegAff\n",
              "0            A     NaN      NaN    NaN    NaN\n",
              "1      ABANDON     NaN  Negativ    NaN    NaN\n",
              "2  ABANDONMENT     NaN  Negativ    NaN    NaN\n",
              "3        ABATE     NaN  Negativ    NaN    NaN\n",
              "4    ABATEMENT     NaN      NaN    NaN    NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8sd-iln40Zs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#we need to get rid of nan values, only take explicitly labeled data\n",
        "positive = df['Entry'][df['Positiv']=='Positiv']\n",
        "positive.dropna(inplace=True)\n",
        "\n",
        "negative = df['Entry'][df['Negativ']=='Negativ']\n",
        "negative.dropna(inplace=True)\n",
        "\n",
        "pos_aff = df['Entry'][df['PosAff']=='PosAff']\n",
        "pos_aff.dropna(inplace=True)\n",
        "\n",
        "neg_aff = df['Entry'][df['NegAff']=='NegAff']\n",
        "neg_aff.dropna(inplace=True)\n",
        "\n",
        "#we should also convert each word list to lowercase\n",
        "#and the pandas series object to a list\n",
        "positive = positive.str.lower().tolist()\n",
        "negative = negative.str.lower().tolist()\n",
        "pos_aff = pos_aff.str.lower().tolist()\n",
        "neg_aff = neg_aff.str.lower().tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlCo4iwt426s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "3ba05301-6300-4d33-d8e6-b4b38911f0a0"
      },
      "source": [
        "#according to the website, there are 1915 pos, 2291 neg\n",
        "len_pos = len(positive)\n",
        "len_neg = len(negative)\n",
        "\n",
        "print('There are {} positive words in the positive word list.'.format(len_pos))\n",
        "print('There are {} negative words in the negative word list.'.format(len_neg), '\\n')\n",
        "\n",
        "#and there should be 126 pos_aff, 193 neg_aff words\n",
        "print('There are {} positive words in the positive affect word list.'.format(len(pos_aff)))\n",
        "print('There are {} negative words in the negative affect word list.'.format(len(neg_aff)), '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1915 positive words in the positive word list.\n",
            "There are 2291 negative words in the negative word list. \n",
            "\n",
            "There are 126 positive words in the positive affect word list.\n",
            "There are 193 negative words in the negative affect word list. \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZE0ZSE246Kh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "954426a8-f80a-48b5-8813-8492142e148e"
      },
      "source": [
        "print(positive[:5], '\\n')\n",
        "print(negative[:5])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['abide', 'ability', 'able', 'abound', 'absolve'] \n",
            "\n",
            "['abandon', 'abandonment', 'abate', 'abdicate', 'abhor']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5sma7mR48UE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "positive.extend(pos_aff)\n",
        "negative.extend(neg_aff)\n",
        "\n",
        "#now convert to a set to remove any duplicates\n",
        "positive = list(set(positive))\n",
        "negative = list(set(negative))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WsqLKik4-n4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c62ef80f-46e5-41b7-d223-6e4007e4bf40"
      },
      "source": [
        "print('There are {} more positive words in the positive word list now.'.format(len(positive) - len_pos))\n",
        "print('There are {} more negative words in the negative word list now.'.format(len(negative) - len_neg), '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 24 more positive words in the positive word list now.\n",
            "There are 27 more negative words in the negative word list now. \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJQ1GjVl5Ame",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "cb1df70f-e049-434f-fb94-b2174800ba6d"
      },
      "source": [
        "#check for common positive words\n",
        "print('good' in positive)\n",
        "print('great' in positive)\n",
        "print('happy' in positive)\n",
        "print('love' in positive)\n",
        "print('excellent' in positive, '\\n')\n",
        "\n",
        "#check for common negative words\n",
        "print('bad' in negative)\n",
        "print('terrible' in negative)\n",
        "print('sad' in negative)\n",
        "print('depressed' in negative)\n",
        "print('tired' in negative)\n",
        "print('bored' in negative)\n",
        "print('alone' in negative)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True \n",
            "\n",
            "True\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N84gGZGz5FkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "positive.append('good')\n",
        "positive.append('great')\n",
        "positive.append('love')\n",
        "positive.append('happy')\n",
        "positive.append('like')\n",
        "\n",
        "#and now depressed, tired, bored, alone, plus some others\n",
        "negative.append('depressed')\n",
        "negative.append('tired')\n",
        "negative.append('bored')\n",
        "negative.append('alone')\n",
        "negative.append('annoying')\n",
        "negative.append('irritate')\n",
        "negative.append('irritated')\n",
        "negative.append('bother')\n",
        "negative.append('bothered')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKtchXJK5MbA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "a0e7ab83-66aa-4883-e71f-d3cb98b0379f"
      },
      "source": [
        "#count positive words unions\n",
        "rslt_df['pos_in_tokens'] =  rslt_df.tokenized_answer.apply(lambda x : list_in_text(positive, x))\n",
        "rslt_df['neg_in_tokens'] =  rslt_df.tokenized_answer.apply(lambda x : list_in_text(negative, x))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6H43WuSqBtoG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "59ee25b7-8319-4ee4-f905-25f33c24a4be"
      },
      "source": [
        "rslt_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>personId</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>tokenized_answer</th>\n",
              "      <th>word_count</th>\n",
              "      <th>fill</th>\n",
              "      <th>single</th>\n",
              "      <th>plural</th>\n",
              "      <th>third</th>\n",
              "      <th>absolute</th>\n",
              "      <th>pos_in_tokens</th>\n",
              "      <th>neg_in_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>300</td>\n",
              "      <td>how are you doing today</td>\n",
              "      <td>good</td>\n",
              "      <td>[good]</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>300</td>\n",
              "      <td>where are you from originally</td>\n",
              "      <td>atlanta georgia</td>\n",
              "      <td>[atlanta, georgia]</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>300</td>\n",
              "      <td>why'd you move to l_a</td>\n",
              "      <td>um my parents are from here um</td>\n",
              "      <td>[um, my, parents, are, from, here, um]</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>300</td>\n",
              "      <td>how do you like l_a</td>\n",
              "      <td>i love it</td>\n",
              "      <td>[i, love, it]</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>300</td>\n",
              "      <td>what are some things you really like about l_a</td>\n",
              "      <td>i like the weather i like the opportunities u...</td>\n",
              "      <td>[i, like, the, weather, i, like, the, opportun...</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8698</th>\n",
              "      <td>390</td>\n",
              "      <td>that's so good to hear</td>\n",
              "      <td>mm</td>\n",
              "      <td>[mm]</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8699</th>\n",
              "      <td>390</td>\n",
              "      <td>is there anything you regret</td>\n",
              "      <td>um hm no um except meeting that one woman uh</td>\n",
              "      <td>[um, hm, no, um, except, meeting, that, one, w...</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8700</th>\n",
              "      <td>390</td>\n",
              "      <td>what advice would you give to yourself ten or ...</td>\n",
              "      <td>uh i don't know probably try a little harder ...</td>\n",
              "      <td>[uh, i, do, n't, know, probably, try, a, littl...</td>\n",
              "      <td>66</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8701</th>\n",
              "      <td>390</td>\n",
              "      <td>tell me how you spend your ideal weekend</td>\n",
              "      <td>oh um getting out of town um going going away...</td>\n",
              "      <td>[oh, um, getting, out, of, town, um, going, go...</td>\n",
              "      <td>22</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8702</th>\n",
              "      <td>390</td>\n",
              "      <td>what are you most proud of in your life</td>\n",
              "      <td>um well my daughter's a great source of pride...</td>\n",
              "      <td>[um, well, my, daughter, 's, a, great, source,...</td>\n",
              "      <td>49</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8703 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     personId  ... neg_in_tokens\n",
              "0         300  ...             0\n",
              "1         300  ...             0\n",
              "2         300  ...             0\n",
              "3         300  ...             0\n",
              "4         300  ...             0\n",
              "...       ...  ...           ...\n",
              "8698      390  ...             0\n",
              "8699      390  ...             0\n",
              "8700      390  ...             2\n",
              "8701      390  ...             0\n",
              "8702      390  ...             0\n",
              "\n",
              "[8703 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    }
  ]
}